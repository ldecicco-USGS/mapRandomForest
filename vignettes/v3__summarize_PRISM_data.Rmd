---
title: "Part 3: Summarize PRISM data"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{3. Summarize PRISM data}
  \usepackage[utf8]{inputenc}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This example shows how the functions modeled after Brian Breaker's scripts may be used to recreate the data files used in his random forest model for the Mississippi Alluvial Plain (MAP) project area. The model is referred to hereafter as the 'RFMAP' model.

The code in this vignette assumes that an earlier vignette has been run and that the file `monthly_discharge.csv` has been generated in that step.

# Initialize environment and read/reproject shapefile

It is more efficient to read and reproject the shapefile once; we'll read in the shapefile and an example raster containing PRISM data, then reproject the shapefile so that it is in the same projection as the rasters.

```{r Generate_site_list}
# the 'magrittr' package provides the 'pipe' operator ('%>%') used throughout the vignettes
library(magrittr)

# The monthly PRISM dataset is many gigabytes of data; download this locally and change the
# path descriptor as appropriate if running the vignettes locally
path_to_PRISM_data <- "g:\\PRISM_Monthly_4k"

test_PRISM_file   <- paste(path_to_PRISM_data,"ppt","PRISM_ppt_stable_4kmM2_1896_bil.bil",sep="/")
test_PRISM_raster <- raster::raster(test_PRISM_file)
# maximum number of "clusters" to create for parallel processing; usually 5-10 on a laptop
max_clusters      <- 10
```

Read in previously calculated discharge data, making sure that we have a date we can use later on in the processing. Note also that we're filtering discharge values to exclude:

* discharge values from the year 2018 or later
* monthly values calculated for a month with less than 25 missing values
* monthly values calculated for gages on streams subject to significant regulation

```{r read in previously calculated values}
# read in previously calculated monthly discharge values
flow_data <- readr::read_csv('monthly_discharge.csv')

# we currently have no PRISM data for 2018; must subset date values
# set day to middle of month; parse as date; filter
flow_data$yyyymmdd <- lubridate::ymd(paste(flow_data$date,"15",sep="-"))

# eliminate data from 2018, mean values calculated from less than 25 values, or values
# associated with regulated flow or significant flow diversions
flow_data <- flow_data %>% 
               dplyr::filter(yyyymmdd < lubridate::ymd("2018-01-01")) %>%
               dplyr::filter(count_non_na > 24 ) %>%
               dplyr::filter(!is_regulated)

# read in shapefile; sites are identified by the attribute 'site_no'
shapefile_name <- system.file("extdata","sitesAll.shp", package = "mapRandomForest")
sites_sp       <- raster::shapefile(shapefile_name)

# reproject gage site shapefile to align with the projection used with the PRISM data files
sites_reprojected_sp <- sp::spTransform(sites_sp, CRSobj = test_PRISM_raster@crs)

```


Next, we create a wrapper function around the package function `getRasterMean`, in order to help in parallelizing the calculation.

```{r}

getRasterMean_wrapper <- function(site_no, month, year, dataname='ppt') {
  
  # during parallel operations, anything written to std_out is lost; write to 
  # a logile instead so we have some idea of the progress being made
  write(file="logfile.txt", append=TRUE, 
        x=paste(system("hostname"),site_no, month, year,dataname))
  
  path <- paste(path_to_PRISM_data,'/',dataname,'/',sep="")
  raster_filename <- list.files(path, 
                                pattern=glob2rx(paste("*",dataname,"*stable*",as.character(year),
                                                as.character(month),"*.bil",sep="")),
                                full.names=TRUE)
  
  shp <- sites_reprojected_sp[sites_reprojected_sp@data$site_no==site_no, ]
  
  # crude error trapping in the event that a particular PRISM image file cannot be found
  if (length(raster_filename) > 0 ) {
    if (file.exists( raster_filename) ) {
      value <- getRasterMean(raster_filename, shp)
    } else {
      write(file="logfile.txt", append=TRUE, paste("**ERROR** - file doesn't exist:", raster_filename))
      value <- NA
    }
  } else {
    write(file="logfile.txt", append=TRUE, paste("**ERROR** - file not found:", raster_filename))
    value <- NA
  }  
  
  return(as.numeric(value))
  
}


```

# Set up parallel computing environment

```{r setup_parallel_computing_environment, eval=FALSE}

cl <- parallel::makeCluster(max_clusters)

# must register parallel backend with the 'foreach' package
doParallel::registerDoParallel(cl)
site_numbers <- unique(sites_reprojected_sp$site_no)
```

# Summarize mean PRISM precipitation values

```{r summarize_precipitation, eval=FALSE}

dataname <- "ppt"

file.remove("logfile.txt")

mean_ppt_values <- foreach::foreach(b=site_numbers, .combine=rbind) %:%

  foreach::foreach(a=dplyr::filter(flow_data, site_no==b)$date,.combine=rbind,
                                        .packages=c("sp","dplyr","raster","stringr",
                                          "data.table","lubridate","velox","mapRandomForest")) %dopar% {
    
    value <- getRasterMean_wrapper(site_no=b, 
                                   month=unlist(stringr::str_split(a,"-"))[2],
                                   year=unlist(stringr::str_split(a,"-"))[1],
                                   dataname=dataname )

    data.frame(site_no=b,date=a,value=value)
                                          }
readr::write_csv(mean_ppt_values,"mean_ppt_values.csv")
```

# Summarize mean PRISM minimum air temperature values

```{r summarize_minimum_air_temps, eval=FALSE}
dataname <- "tmin"

mean_tmin_values <- foreach::foreach(b=site_numbers, .combine=rbind) %:%

  foreach::foreach(a=dplyr::filter(flow_data, site_no==b)$date,.combine=rbind,
                                        .packages=c("sp","dplyr","raster","stringr",
                                          "data.table","lubridate","velox","mapRandomForest")) %dopar% {
    
    value <- getRasterMean_wrapper(site_no=b, 
                                   month=unlist(stringr::str_split(a,"-"))[2],
                                   year=unlist(stringr::str_split(a,"-"))[1],
                                   dataname=dataname )

    data.frame(site_no=b,date=a,value=value)
                                          }
readr::write_csv(mean_tmin_values,"mean_tmin_values.csv")
```

# Summarize mean PRISM maximum air temperature values

```{r summarize_max_air_temps, eval=FALSE}
dataname <- "tmax"

mean_tmax_values <- foreach::foreach(b=site_numbers, .combine=rbind) %:%

  foreach::foreach(a=dplyr::filter(flow_data, site_no==b)$date,.combine=rbind,
                                        .packages=c("sp","dplyr","raster","stringr",
                                          "data.table","lubridate","velox","mapRandomForest")) %dopar% {
    
    value <- getRasterMean_wrapper(site_no=b, 
                                   month=unlist(stringr::str_split(a,"-"))[2],
                                   year=unlist(stringr::str_split(a,"-"))[1],
                                   dataname=dataname )

    data.frame(site_no=b,date=a,value=value)
  }

readr::write_csv(mean_tmax_values,"mean_tmax_values.csv")
```


# Summarize mean PRISM mean air temperature values

```{r, summarize_mean_air_temps, eval=FALSE}
dataname <- "tmean"

mean_tmean_values <- foreach::foreach(b=site_numbers, .combine=rbind) %:%

  foreach::foreach(a=dplyr::filter(flow_data, site_no==b)$date,.combine=rbind,
                                        .packages=c("sp","dplyr","raster","stringr",
                                          "data.table","lubridate","velox","mapRandomForest")) %dopar% {
    
    value <- getRasterMean_wrapper(site_no=b, 
                                   month=unlist(stringr::str_split(a,"-"))[2],
                                   year=unlist(stringr::str_split(a,"-"))[1],
                                   dataname=dataname )

    data.frame(site_no=b,date=a,value=value)
  }

readr::write_csv(mean_tmean_values,"mean_tmean_values.csv")
```


```{r stop_cluster, eval=FALSE}
parallel::stopCluster(cl)
```

```{r Read_in_csv_values}
library(mapRandomForest)

mean_tmin_values <- readr::read_csv("mean_tmin_values.csv") %>%
                           dplyr::group_by(site_no) %>%
                           dplyr::mutate(block_id=identify_contiguous(date)) %>%
                           dplyr::mutate(group_id=paste(site_no,block_id,sep="_"))

mean_tmax_values <- readr::read_csv("mean_tmax_values.csv") %>%
                           dplyr::group_by(site_no) %>%
                           dplyr::mutate(block_id=identify_contiguous(date)) %>%
                           dplyr::mutate(group_id=paste(site_no,block_id,sep="_"))

mean_tmean_values <- readr::read_csv("mean_tmean_values.csv") %>%
                           dplyr::group_by(site_no) %>%
                           dplyr::mutate(block_id=identify_contiguous(date)) %>%
                           dplyr::mutate(group_id=paste(site_no,block_id,sep="_"))

mean_ppt_values <- readr::read_csv("mean_ppt_values.csv") %>% 
                     dplyr::group_by(site_no) %>%
                     dplyr::mutate(block_id=identify_contiguous(date)) %>%
                     dplyr::mutate(group_id=paste(site_no,block_id,sep="_"))


```


# Create lagged values for precipitation data

```{r create_lagged_values_for_precip}

mean_ppt_values_lagged <- mean_ppt_values %>%
                     dplyr::group_by(group_id) %>%
                     dplyr::mutate(precip_lag_1m=lag(value,1)) %>%
                     dplyr::mutate(precip_lag_2m=lag(value,2)) %>%
                     dplyr::mutate(precip_lag_3m=lag(value,3)) %>%
                     dplyr::mutate(precip_lag_4m=lag(value,4)) %>%
                     dplyr::mutate(precip_lag_5m=lag(value,5)) %>%
                     dplyr::mutate(precip_lag_6m=lag(value,6)) 

mean_ppt_values_lagged$precip_sum_6m <- with(mean_ppt_values_lagged,
                                             precip_lag_1m +
                                             precip_lag_2m +
                                             precip_lag_3m +
                                             precip_lag_4m +
                                             precip_lag_5m +
                                             precip_lag_6m )

mean_ppt_values_lagged$precip <- mean_ppt_values_lagged$value
mean_ppt_values_lagged$value <- NULL

mean_ppt_values_lagged <- mean_ppt_values_lagged %>%
                            dplyr::filter(!is.na(precip_sum_6m))

readr::write_csv(mean_ppt_values_lagged, "mean_ppt_values_w_lag.csv")

```


# Create lagged values for minimum air temperature data

```{r create_lagged_values_for_minimum_air_temperature}

mean_tmin_values_lagged <- mean_tmin_values %>%
                     dplyr::group_by(group_id) %>%
                     dplyr::mutate(tmin_lag_1m=lag(value,1)) %>%
                     dplyr::filter(!is.na(tmin_lag_1m))


mean_tmin_values_lagged <- mean_tmin_values_lagged %>%
                     dplyr::group_by(group_id) %>%
                     dplyr::mutate(tmin_lag_2m=lag(value,2)) %>%
                     dplyr::filter(!is.na(tmin_lag_2m))

mean_tmin_values_lagged$tmin <- mean_tmin_values_lagged$value
mean_tmin_values_lagged$value <- NULL

readr::write_csv(mean_tmin_values_lagged, "mean_tmin_values_w_lag.csv")

```

# Create lagged values for maximum air temperature data

```{r create_lagged_values_for_maximum_air_temperature}

mean_tmax_values_lagged <- mean_tmax_values %>%
                     dplyr::group_by(group_id) %>%
                     dplyr::mutate(tmax_lag_1m=lag(value,1)) %>%
                     dplyr::filter(!is.na(tmax_lag_1m))


mean_tmax_values_lagged <- mean_tmax_values_lagged %>%
                     dplyr::group_by(group_id) %>%
                     dplyr::mutate(tmax_lag_2m=lag(value,2)) %>%
                     dplyr::filter(!is.na(tmax_lag_2m))

mean_tmax_values_lagged$tmax <- mean_tmax_values_lagged$value
mean_tmax_values_lagged$value <- NULL

readr::write_csv(mean_tmax_values_lagged, "mean_tmax_values_w_lag.csv")

```

# Create lagged values for mean air temperature data

```{r create_lagged_values_for_mean_air_temperature}

mean_tmean_values_lagged <- mean_tmean_values %>%
                     dplyr::group_by(group_id) %>%
                     dplyr::mutate(tmean_lag_1m=lag(value,1)) %>%
                     dplyr::filter(!is.na(tmean_lag_1m))


mean_tmean_values_lagged <- mean_tmean_values_lagged %>%
                     dplyr::group_by(group_id) %>%
                     dplyr::mutate(tmean_lag_2m=lag(value,2)) %>%
                     dplyr::filter(!is.na(tmean_lag_2m))

mean_tmean_values_lagged$tmean <- mean_tmean_values_lagged$value
mean_tmean_values_lagged$value <- NULL

readr::write_csv(mean_tmean_values_lagged, "mean_tmean_values_w_lag.csv")

```


